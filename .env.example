# API Configuration for The Last Vote
# ========================================
# This file shows all available environment variables.
# Copy this file to .env.local and configure as needed.
# ========================================

# ============================================================
# BACKEND API KEY (Server-side - REQUIRED FOR API MODE)
# ============================================================
# Get your OpenRouter API key from: https://openrouter.ai/keys
# This is used by BOTH the local dev server AND Vercel production
# NEVER commit this key to git!
OPENROUTER_API_KEY=your-openrouter-api-key-here

# ============================================================
# AI MODEL SELECTION
# ============================================================
# Choose which OpenRouter model to use for candidate responses.
# See available models at: https://openrouter.ai/models
#
# Free tier options (50 requests/day):
# - xiaomi/mimo-v2-flash:free (default - fast, capable)
# - google/gemma-2-9b-it:free (good quality)
# - mistralai/mistral-7b-instruct:free (reliable)
# - meta-llama/llama-3-8b-instruct:free (popular)
#
# Paid options (with credits):
# - anthropic/claude-3.5-haiku (fast, high quality)
# - openai/gpt-4o-mini (excellent quality)
# - google/gemini-flash-1.5 (fast, affordable)
OPENROUTER_MODEL=xiaomi/mimo-v2-flash:free

# ============================================================
# LOCAL DEVELOPMENT SERVER CONFIGURATION
# ============================================================
# Port for the local API server (default: 3001)
API_PORT=3001

# ============================================================
# API MODE SELECTION
# ============================================================
# Controls which mode the API client uses:
#
# Option 1: FALLBACK mode (default - no API key needed)
# - Leave empty or comment out VITE_API_MODE
# - Uses pre-written Thai responses (15 total)
# - Works offline, no costs, instant responses
#
# Option 2: MOCK mode (testing UI states)
# - Set VITE_API_MODE=mock
# - Simulated 1-3 second delays
# - Tests loading states without API calls
#
# Option 3: API mode (real AI with OpenRouter)
# - Set VITE_API_MODE=api
# - Requires OPENROUTER_API_KEY above
# - Real AI-generated responses from candidates
# - Free tier: 50 requests/day, 20 requests/minute

# Choose your mode:
VITE_API_MODE=api

# ============================================================
# API ENDPOINT CONFIGURATION
# ============================================================
# Local development: Uses Vite proxy (automatically proxies /api to localhost:3001)
# Production: Set to your deployed Vercel backend URL

# For local dev (Vite proxy handles this automatically):
# Leave VITE_API_URL commented out - Vite proxies /api to http://localhost:3001

# For production deployment on Vercel:
# Uncomment and set to your Vercel domain:
# VITE_API_URL=https://your-project.vercel.app/api/chat

# ============================================================
# OPTIONAL CONFIGURATION
# ============================================================
# Override request timeout in milliseconds (default: 10000)
# VITE_API_TIMEOUT=10000

# Override max retry attempts (default: 3)
# VITE_API_MAX_RETRIES=3

# Override initial retry delay in milliseconds (default: 1000)
# VITE_API_RETRY_DELAY=1000
